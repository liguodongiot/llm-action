



## LLM选择标准

在选本地化的LLM之前，我们先根据实际情况定义一些选择标准：

- 归纳优先：我们不需要LLM在各个方面都很优秀，不需要它们会很强的coding和复杂逻辑推理能力，RAG最重要的还是出色的归纳能力；
- 体量考虑：不要太大，最好在13B及以下，因为再大就需要一张A100等专业显卡，或者要多张消费级显卡。我们的目标是一张RTX 4090可以解决问题，对很多客户来说，A卡很难买，而且价格太高了；
- 中文能力：我们主要面对的还是中文业务，所以Llama对我们还是成本太高，如果自己做大量训练的话。










## 实践经验

### 坑点

- 使用 Hugging Face Transformers 进行多机多卡训练时，反复加载模型，设置卡等，不然可能导致代码错乱，比如：保存模型不成功，保存模型不完整等等。
- 使用Megatron-Deepspeed、Hugging Face Transformers (Deepspeed)进行分布式训练时，使用一些共享存储可能会遇到问题，比如一个进程写入文件之后，另一个进程无法马上读取到文件。












